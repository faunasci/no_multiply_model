# Shift-Add Neural Networks Comparison

[English](#english) | [Portugu√™s](#portugu√™s) | [Fran√ßais](#fran√ßais)

---

## English

This project explores the implementation of **Shift-Add Neural Networks** as an alternative to standard multiplication-based neural networks. Inspired by the Ancient Egyptian multiplication method (multiplication by doubling and adding), this model replaces standard linear layers with a quantized version where weights are powers of two.

### üöÄ Key Concepts
- **Multiplication-free Layers**: By constraining weights to be powers of two ($sign \times 2^n$), multiplications in the forward pass can be replaced by more efficient bit-shift operations and additions.
- **Quantization**: Weights are quantized to the nearest power of two during the forward pass using a Straight-Through Estimator (STE).
- **Hardware Efficiency**: Shift-add operations are significantly more energy-efficient and faster on specialized hardware (FPGAs, custom ASICs).

### üìÅ Project Structure
- **`src/`**: Source code containing `add_model.py`.
- **`results/`**: Output directory for metrics and plots.
- `.gitignore` & `requirements.txt`: Standard project configuration.

### ÔøΩÔ∏è Usage
1. `pip install -r requirements.txt`
2. `python src/add_model.py`

---

## Portugu√™s

Este projeto explora a implementa√ß√£o de **Redes Neurais Shift-Add** como uma alternativa √†s redes neurais padr√£o baseadas em multiplica√ß√£o. Inspirado no m√©todo de multiplica√ß√£o eg√≠pcio (multiplica√ß√£o por dobros e adi√ß√µes), este modelo substitui as camadas lineares padr√£o por uma vers√£o quantizada onde os pesos s√£o pot√™ncias de dois.

### üöÄ Conceitos Chave
- **Camadas sem Multiplica√ß√£o**: Ao restringir os pesos a pot√™ncias de dois ($sinal \times 2^n$), as multiplica√ß√µes no "forward pass" podem ser substitu√≠das por opera√ß√µes de bit-shift e adi√ß√µes mais eficientes.
- **Quantiza√ß√£o**: Os pesos s√£o quantizados para a pot√™ncia de dois mais pr√≥xima durante o processamento usando um Straight-Through Estimator (STE).
- **Efici√™ncia de Hardware**: Opera√ß√µes de shift-add s√£o significativamente mais eficientes energeticamente e r√°pidas em hardware especializado (FPGAs, ASICs customizados).

### üìÅ Estrutura do Projeto
- **`src/`**: C√≥digo fonte contendo `add_model.py`.
- **`results/`**: Diret√≥rio de sa√≠da para m√©tricas e gr√°ficos.
- `.gitignore` & `requirements.txt`: Configura√ß√£o padr√£o do projeto.

---

## Fran√ßais

Ce projet explore l'impl√©mentation des **R√©seaux de Neurones Shift-Add** comme alternative aux r√©seaux de neurones standard bas√©s sur la multiplication. Inspir√© par la m√©thode de multiplication √©gyptienne (multiplication par doublement et addition), ce mod√®le remplace les couches lin√©aires standard par une version quantifi√©e o√π les poids sont des puissances de deux.

### ÔøΩ Concepts Cl√©s
- **Couches sans Multiplication**: En contraignant les poids √† √™tre des puissances de deux ($signe \times 2^n$), les multiplications peuvent √™tre remplac√©es par des op√©rations de d√©calage de bits (bit-shift) et des additions plus efficaces.
- **Quantification**: Les poids sont quantifi√©s √† la puissance de deux la plus proche pendant la passe avant en utilisant un "Straight-Through Estimator" (STE).
- **Efficacit√© Mat√©rielle**: Les op√©rations shift-add sont nettement plus √©conomes en √©nergie et plus rapides sur du mat√©riel sp√©cialis√© (FPGAs, ASICs personnalis√©s).

### ÔøΩ Structure du Projet
- **`src/`**: Code source contenant `add_model.py`.
- **`results/`**: R√©pertoire de sortie pour les m√©triques et les graphiques.
- `.gitignore` & `requirements.txt`: Configuration standard du projet.
